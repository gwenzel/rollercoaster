# Roller Coaster Data Crawlers

This directory contains web scraping tools for collecting roller coaster data from multiple sources.

## ğŸ“ Directory Structure

```
crawler/
â”œâ”€â”€ captaincoaster/      # Captain Coaster review crawler
â”‚   â”œâ”€â”€ crawler.py       # Main crawler for captaincoaster.com
â”‚   â”œâ”€â”€ test_crawler.py  # Unit tests
â”‚   â”œâ”€â”€ quick_scrape.py  # Quick test script
â”‚   â””â”€â”€ CRAWLER_README.md
â”œâ”€â”€ rideforcesdb/        # Ride Forces DB G-force crawler
â”‚   â”œâ”€â”€ rfdb_crawler.py  # Main crawler for rideforcesdb.com
â”‚   â”œâ”€â”€ rfdb_browse.html # Browser inspection tool
â”‚   â””â”€â”€ RFDB_CRAWLER_README.md
â”œâ”€â”€ shared/              # Shared data processing tools
â”‚   â”œâ”€â”€ process_reviews.py      # Data cleaning & sentiment analysis
â”‚   â”œâ”€â”€ visualize_data.py       # Data visualization dashboard
â”‚   â””â”€â”€ PROCESSING_README.md
â””â”€â”€ data/                # Output directory for collected data
```

## ğŸ¯ Quick Start

### 1. Captain Coaster Reviews
Scrape rider reviews and ratings:
```bash
cd captaincoaster
python crawler.py
```

### 2. Ride Forces DB (G-forces)
Collect G-force measurements:
```bash
cd rideforcesdb
python rfdb_crawler.py
```

### 3. Process Collected Data
Clean and analyze reviews:
```bash
cd shared
python process_reviews.py
```

### 4. Visualize Results
Generate charts and insights:
```bash
cd shared
python visualize_data.py
```

## ğŸ“Š Data Sources

| Source | Data Type | Records | Fields |
|--------|-----------|---------|---------|
| **Captain Coaster** | Reviews & Ratings | 73,981+ | 17 fields |
| **Ride Forces DB** | G-force Measurements | TBD | Peak forces, duration |

## ğŸ› ï¸ Installation

Each subfolder has its own `requirements.txt`:

```bash
# Install Captain Coaster dependencies
pip install -r captaincoaster/requirements_crawler.txt

# Install Ride Forces DB dependencies (includes Selenium)
pip install -r rideforcesdb/requirements_rfdb.txt

# Shared tools use standard pandas/matplotlib
pip install pandas matplotlib seaborn textblob
```

## ğŸ“– Documentation

- **Captain Coaster**: See `captaincoaster/CRAWLER_README.md` and `captaincoaster/QUICKSTART.md`
- **Ride Forces DB**: See `rideforcesdb/RFDB_CRAWLER_README.md`
- **Data Processing**: See `shared/PROCESSING_README.md` and `shared/DATA_PROCESSING_GUIDE.md`

## ğŸ¢ Integration with Main App

Collected data can be used to:
1. **Train ML models** - Predict ratings from G-force profiles
2. **Enhance simulations** - Real-world validation of physics models
3. **Recommend coasters** - Sentiment analysis for recommendations
4. **Compare designs** - Benchmark custom coasters against real ones

## ğŸ”„ Workflow

```
1. Scrape Reviews           2. Scrape G-forces
   (captaincoaster/)           (rideforcesdb/)
         â†“                            â†“
    reviews.csv              gforce_data.csv
         â†“                            â†“
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
            3. Combine & Process
               (shared/)
                      â†“
         combined_dataset.csv
                      â†“
            4. Train ML Models
                      â†“
         5. Integrate with app.py
```

## ğŸ“ Notes

- Captain Coaster crawler saves progress every 10 pages
- Ride Forces DB uses Selenium for JavaScript-heavy pages
- All crawlers respect rate limits (1-2 second delays)
- Data is deduplicated by unique IDs before processing

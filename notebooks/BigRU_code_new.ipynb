{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BiGRU Model for Roller Coaster Rating Prediction\n",
    "\n",
    "This notebook trains a Bidirectional GRU model to predict roller coaster ratings from accelerometer data.\n",
    "\n",
    "**Data Source**: Complete coaster mapping with perfect matches, duplicate averaging, and airtime calculation.\n",
    "\n",
    "**Key Features**:\n",
    "- Loads data from `complete_coaster_mapping.csv`\n",
    "- Filters for perfect matches (≥95% similarity)\n",
    "- Averages duplicate coaster names\n",
    "- Calculates airtime features from vertical g-forces\n",
    "- Trains BiGRU model with sequence + airtime features\n",
    "- Full training pipeline in one notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "vInb8-BGgUWt",
    "outputId": "0aa92d49-ecd7-42fd-926b-ad4ab8f82365"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "[OK] Configuration and data preparation functions loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# IMPORTS AND CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "# Data paths\n",
    "MAPPING_CSV = 'ratings_data/complete_coaster_mapping.csv'\n",
    "\n",
    "# Model hyperparameters\n",
    "SEQUENCE_LENGTH = 1000\n",
    "ACCEL_CHANNELS = 3\n",
    "AIRTIME_FEATURE_COUNT = 4\n",
    "HIDDEN_DIM = 128\n",
    "NUM_LAYERS = 2\n",
    "DROPOUT_RATE = 0.3\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 1e-4\n",
    "NUM_EPOCHS = 100\n",
    "WEIGHT_DECAY = 1e-5\n",
    "\n",
    "# Data filtering\n",
    "MIN_CSV_COUNT = 1\n",
    "MIN_RATINGS = 10\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ============================================================================\n",
    "# DATA PREPARATION FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def load_complete_mapping(csv_path=MAPPING_CSV):\n",
    "    \"\"\"Load the complete coaster mapping CSV.\"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(f\"\\n[OK] Loaded {len(df)} coasters from complete mapping\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def filter_perfect_matches(df):\n",
    "    \"\"\"Filter for perfect matches only (>=95% similarity).\"\"\"\n",
    "    perfect = df[df['match_type'] == 'perfect'].copy()\n",
    "    print(f\"[OK] Filtered to {len(perfect)} coasters with perfect name matches\")\n",
    "    return perfect\n",
    "\n",
    "\n",
    "def aggregate_duplicates(df):\n",
    "    \"\"\"Average ratings for duplicate coaster names.\"\"\"\n",
    "    grouped = df.groupby('coaster_name').agg({\n",
    "        'avg_rating': 'mean',\n",
    "        'total_ratings': 'sum',\n",
    "        'csv_count': 'max',\n",
    "        'full_path': 'first',\n",
    "        'rfdb_park_folder': 'first',\n",
    "        'rfdb_coaster_folder': 'first',\n",
    "        'coaster_id': 'first',\n",
    "        'ratings_coaster': 'first',\n",
    "        'ratings_park': 'first',\n",
    "        'match_type': 'first'\n",
    "    }).reset_index()\n",
    "    \n",
    "    duplicates = df['coaster_name'].value_counts()\n",
    "    duplicates = duplicates[duplicates > 1].index\n",
    "    \n",
    "    if len(duplicates) > 0:\n",
    "        print(f\"\\n[!] Found {len(duplicates)} duplicate coaster names:\")\n",
    "        for coaster_name in duplicates:\n",
    "            dupes = df[df['coaster_name'] == coaster_name].sort_values('csv_count', ascending=False)\n",
    "            best_path = dupes.iloc[0]['full_path']\n",
    "            best_csv_count = dupes.iloc[0]['csv_count']\n",
    "            avg_rating = dupes['avg_rating'].mean()\n",
    "            \n",
    "            grouped.loc[grouped['coaster_name'] == coaster_name, 'full_path'] = best_path\n",
    "            grouped.loc[grouped['coaster_name'] == coaster_name, 'csv_count'] = best_csv_count\n",
    "            grouped.loc[grouped['coaster_name'] == coaster_name, 'avg_rating'] = avg_rating\n",
    "            \n",
    "            print(f\"  - {coaster_name}: {len(dupes)} entries -> avg rating {avg_rating:.2f}\")\n",
    "    \n",
    "    print(f\"\\n[OK] Final dataset: {len(grouped)} unique coasters\")\n",
    "    return grouped\n",
    "\n",
    "\n",
    "def get_accelerometer_files(full_path):\n",
    "    \"\"\"Get list of accelerometer CSV files from path.\"\"\"\n",
    "    # Normalize path for Windows/Unix compatibility\n",
    "    full_path = full_path.replace('\\\\', '/')\n",
    "    csv_files = glob.glob(f\"{full_path}/*.csv\")\n",
    "    return sorted(csv_files)\n",
    "\n",
    "\n",
    "def load_last_accelerometer_file(full_path):\n",
    "    \"\"\"Load the last CSV file from the path.\"\"\"\n",
    "    # Normalize path separators\n",
    "    full_path = full_path.replace('\\\\', '/')\n",
    "    \n",
    "    csv_files = get_accelerometer_files(full_path)\n",
    "    \n",
    "    if not csv_files:\n",
    "        # Try checking if path exists\n",
    "        if not os.path.exists(full_path):\n",
    "            print(f\"[!] Path does not exist: {full_path}\")\n",
    "        return None\n",
    "    \n",
    "    last_file = csv_files[-1]\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(last_file)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {last_file}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def calculate_airtime(accel_df, threshold=-0.1):\n",
    "    \"\"\"Calculate airtime statistics from accelerometer data.\"\"\"\n",
    "    if accel_df is None or 'Vertical' not in accel_df.columns:\n",
    "        return np.zeros(AIRTIME_FEATURE_COUNT, dtype=np.float32)\n",
    "    \n",
    "    vertical = accel_df['Vertical'].values\n",
    "    airtime_mask = vertical < threshold\n",
    "    \n",
    "    total_airtime_samples = np.sum(airtime_mask)\n",
    "    max_negative_g = np.min(vertical) if len(vertical) > 0 else 0\n",
    "    \n",
    "    # Count distinct airtime moments\n",
    "    airtime_moments = 0\n",
    "    in_airtime = False\n",
    "    for is_airtime in airtime_mask:\n",
    "        if is_airtime and not in_airtime:\n",
    "            airtime_moments += 1\n",
    "            in_airtime = True\n",
    "        elif not is_airtime:\n",
    "            in_airtime = False\n",
    "    \n",
    "    # Calculate durations (assuming 10Hz sampling)\n",
    "    sampling_rate = 10\n",
    "    total_airtime = total_airtime_samples / sampling_rate\n",
    "    avg_airtime_duration = total_airtime / airtime_moments if airtime_moments > 0 else 0\n",
    "    \n",
    "    return np.array([total_airtime, max_negative_g, airtime_moments, avg_airtime_duration], dtype=np.float32)\n",
    "\n",
    "\n",
    "def prepare_training_data(mapping_csv=MAPPING_CSV, min_csv_count=MIN_CSV_COUNT, min_ratings=MIN_RATINGS):\n",
    "    \"\"\"Prepare complete training dataset from mapping CSV.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"PREPARING TRAINING DATA FROM COMPLETE MAPPING\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    df = load_complete_mapping(mapping_csv)\n",
    "    df = filter_perfect_matches(df)\n",
    "    \n",
    "    df = df[df['csv_count'] >= min_csv_count]\n",
    "    print(f\"[OK] Filtered to {len(df)} coasters with >={min_csv_count} CSV files\")\n",
    "    \n",
    "    df = df[df['total_ratings'] >= min_ratings]\n",
    "    print(f\"[OK] Filtered to {len(df)} coasters with >={min_ratings} total ratings\")\n",
    "    \n",
    "    df = aggregate_duplicates(df)\n",
    "    df = df.sort_values('avg_rating', ascending=False)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"DATASET STATISTICS\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Total coasters: {len(df)}\")\n",
    "    print(f\"Rating range: {df['avg_rating'].min():.2f} - {df['avg_rating'].max():.2f}\")\n",
    "    print(f\"Average rating: {df['avg_rating'].mean():.2f} +/- {df['avg_rating'].std():.2f}\")\n",
    "    print(f\"Total CSV files: {df['csv_count'].sum()}\")\n",
    "    print(f\"Average CSVs per coaster: {df['csv_count'].mean():.2f}\")\n",
    "    \n",
    "    print(\"\\nTop 5 highest rated:\")\n",
    "    for _, row in df.head(5).iterrows():\n",
    "        print(f\"  {row['coaster_name']:30s} {row['avg_rating']:.2f}* ({row['csv_count']} CSVs)\")\n",
    "    \n",
    "    print(\"\\nBottom 5 lowest rated:\")\n",
    "    for _, row in df.tail(5).iterrows():\n",
    "        print(f\"  {row['coaster_name']:30s} {row['avg_rating']:.2f}* ({row['csv_count']} CSVs)\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "print(\"[OK] Configuration and data preparation functions loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load and Prepare Data\n",
    "\n",
    "Load the complete coaster mapping, filter for perfect matches, and aggregate duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PREPARING TRAINING DATA FROM COMPLETE MAPPING\n",
      "======================================================================\n",
      "\n",
      "[OK] Loaded 1299 coasters from complete mapping\n",
      "[OK] Filtered to 518 coasters with perfect name matches\n",
      "[OK] Filtered to 518 coasters with >=1 CSV files\n",
      "[OK] Filtered to 508 coasters with >=10 total ratings\n",
      "\n",
      "[!] Found 68 duplicate coaster names:\n",
      "  - Boomerang: 13 entries -> avg rating 2.04\n",
      "  - Woodstock Express: 8 entries -> avg rating 1.71\n",
      "  - Dragon: 7 entries -> avg rating 2.08\n",
      "  - Cobra: 7 entries -> avg rating 2.09\n",
      "  - Sea Serpent: 7 entries -> avg rating 1.40\n",
      "  - Corkscrew: 6 entries -> avg rating 2.08\n",
      "  - Goliath: 6 entries -> avg rating 3.80\n",
      "  - Tornado: 6 entries -> avg rating 2.85\n",
      "  - Wildcat: 6 entries -> avg rating 2.55\n",
      "  - Batman The Ride: 5 entries -> avg rating 3.69\n",
      "  - Joker: 5 entries -> avg rating 3.12\n",
      "  - Cyclone: 5 entries -> avg rating 2.50\n",
      "  - Vortex: 5 entries -> avg rating 2.64\n",
      "  - Comet: 4 entries -> avg rating 2.72\n",
      "  - Viper: 4 entries -> avg rating 2.73\n",
      "  - Pandemonium: 4 entries -> avg rating 2.79\n",
      "  - Manta: 3 entries -> avg rating 4.22\n",
      "  - Patriot: 3 entries -> avg rating 2.83\n",
      "  - Vampire: 3 entries -> avg rating 2.73\n",
      "  - Phoenix: 3 entries -> avg rating 3.43\n",
      "  - Little Dipper: 3 entries -> avg rating 1.55\n",
      "  - Anaconda: 3 entries -> avg rating 2.84\n",
      "  - Flash: Vertical Velocity: 3 entries -> avg rating 3.56\n",
      "  - Canyon Blaster: 3 entries -> avg rating 2.19\n",
      "  - Flashback: 3 entries -> avg rating 1.85\n",
      "  - Thunderbolt: 3 entries -> avg rating 2.88  - Thunderbolt: 3 entries -> avg rating 2.88\n",
      "  - Pegasus: 3 entries -> avg rating 2.27\n",
      "  - Bat: 3 entries -> avg rating 2.27\n",
      "  - Hurricane: 3 entries -> avg rating 2.45\n",
      "  - Superman - Ultimate Flight: 3 entries -> avg rating 3.55\n",
      "  - Python: 3 entries -> avg rating 1.62\n",
      "  - Dark Knight: 2 entries -> avg rating 2.36\n",
      "  - Batman: The Ride: 2 entries -> avg rating 2.85\n",
      "  - Revolution: 2 entries -> avg rating 3.00\n",
      "  - Nitro: 2 entries -> avg rating 2.92\n",
      "  - Demon: 2 entries -> avg rating 2.41\n",
      "  - Space Mountain: 2 entries -> avg rating 3.54\n",
      "  - Olympia Looping: 2 entries -> avg rating 3.67\n",
      "  - Invertigo: 2 entries -> avg rating 2.49\n",
      "  - Thunderhawk: 2 entries -> avg rating 2.45\n",
      "  - Giant Dipper: 2 entries -> avg rating 3.28\n",
      "  - Blue Streak: 2 entries -> avg rating 2.87\n",
      "  - Thunderbird: 2 entries -> avg rating 3.85\n",
      "  - Gold Rusher: 2 entries -> avg rating 2.42\n",
      "  - Twister: 2 entries -> avg rating 3.66\n",
      "  - Family Inverted Coaster: 2 entries -> avg rating 2.67\n",
      "  - Shockwave: 2 entries -> avg rating 2.55\n",
      "  - Excalibur: 2 entries -> avg rating 3.52\n",
      "  - Rutschebanen: 2 entries -> avg rating 3.18\n",
      "  - Silver Bullet: 2 entries -> avg rating 3.52\n",
      "  - Flight Deck: 2 entries -> avg rating 2.66\n",
      "  - Raptor: 2 entries -> avg rating 3.91\n",
      "  - Mammut: 2 entries -> avg rating 2.79\n",
      "  - Ninja: 2 entries -> avg rating 2.24\n",
      "  - Medusa: 2 entries -> avg rating 3.82\n",
      "  - Great White: 2 entries -> avg rating 3.53\n",
      "  - Wildfire: 2 entries -> avg rating 4.32\n",
      "  - Leviathan: 2 entries -> avg rating 4.48\n",
      "  - Grizzly: 2 entries -> avg rating 2.52\n",
      "  - Barnstormer: 2 entries -> avg rating 1.88\n",
      "  - Hurler: 2 entries -> avg rating 2.11\n",
      "  - Great Pumpkin Coaster: 2 entries -> avg rating 1.42\n",
      "  - Jack Rabbit: 2 entries -> avg rating 3.33\n",
      "  - Racer (Right): 2 entries -> avg rating 3.01\n",
      "  - Racer (Left): 2 entries -> avg rating 3.02\n",
      "  - Backlot Stunt Coaster: 2 entries -> avg rating 3.01\n",
      "  - Untamed: 2 entries -> avg rating 3.92\n",
      "  - Wilderness Run: 2 entries -> avg rating 1.52\n",
      "\n",
      "[OK] Final dataset: 359 unique coasters\n",
      "\n",
      "======================================================================\n",
      "DATASET STATISTICS\n",
      "======================================================================\n",
      "Total coasters: 359\n",
      "Rating range: 1.06 - 4.90\n",
      "Average rating: 3.29 +/- 0.91\n",
      "Total CSV files: 1198\n",
      "Average CSVs per coaster: 3.34\n",
      "\n",
      "Top 5 highest rated:\n",
      "  Zadra                          4.90* (1 CSVs)\n",
      "  AlpenFury                      4.88* (5 CSVs)\n",
      "  Taiga                          4.87* (4 CSVs)\n",
      "  VelociCoaster                  4.86* (5 CSVs)\n",
      "  ArieForce One                  4.83* (5 CSVs)\n",
      "\n",
      "Bottom 5 lowest rated:\n",
      "  Cocoa Cruiser                  1.29* (1 CSVs)\n",
      "  Kong                           1.28* (3 CSVs)\n",
      "  Howler                         1.22* (2 CSVs)\n",
      "  Spinning Out                   1.17* (2 CSVs)\n",
      "  Euromir                        1.06* (1 CSVs)\n",
      "\n",
      "[OK] Ready to train on 359 coasters\n",
      "\n",
      "  - Pegasus: 3 entries -> avg rating 2.27\n",
      "  - Bat: 3 entries -> avg rating 2.27\n",
      "  - Hurricane: 3 entries -> avg rating 2.45\n",
      "  - Superman - Ultimate Flight: 3 entries -> avg rating 3.55\n",
      "  - Python: 3 entries -> avg rating 1.62\n",
      "  - Dark Knight: 2 entries -> avg rating 2.36\n",
      "  - Batman: The Ride: 2 entries -> avg rating 2.85\n",
      "  - Revolution: 2 entries -> avg rating 3.00\n",
      "  - Nitro: 2 entries -> avg rating 2.92\n",
      "  - Demon: 2 entries -> avg rating 2.41\n",
      "  - Space Mountain: 2 entries -> avg rating 3.54\n",
      "  - Olympia Looping: 2 entries -> avg rating 3.67\n",
      "  - Invertigo: 2 entries -> avg rating 2.49\n",
      "  - Thunderhawk: 2 entries -> avg rating 2.45\n",
      "  - Giant Dipper: 2 entries -> avg rating 3.28\n",
      "  - Blue Streak: 2 entries -> avg rating 2.87\n",
      "  - Thunderbird: 2 entries -> avg rating 3.85\n",
      "  - Gold Rusher: 2 entries -> avg rating 2.42\n",
      "  - Twister: 2 entries -> avg rating 3.66\n",
      "  - Family Inverted Coaster: 2 entries -> avg rating 2.67\n",
      "  - Shockwave: 2 entries -> avg rating 2.55\n",
      "  - Excalibur: 2 entries -> avg rating 3.52\n",
      "  - Rutschebanen: 2 entries -> avg rating 3.18\n",
      "  - Silver Bullet: 2 entries -> avg rating 3.52\n",
      "  - Flight Deck: 2 entries -> avg rating 2.66\n",
      "  - Raptor: 2 entries -> avg rating 3.91\n",
      "  - Mammut: 2 entries -> avg rating 2.79\n",
      "  - Ninja: 2 entries -> avg rating 2.24\n",
      "  - Medusa: 2 entries -> avg rating 3.82\n",
      "  - Great White: 2 entries -> avg rating 3.53\n",
      "  - Wildfire: 2 entries -> avg rating 4.32\n",
      "  - Leviathan: 2 entries -> avg rating 4.48\n",
      "  - Grizzly: 2 entries -> avg rating 2.52\n",
      "  - Barnstormer: 2 entries -> avg rating 1.88\n",
      "  - Hurler: 2 entries -> avg rating 2.11\n",
      "  - Great Pumpkin Coaster: 2 entries -> avg rating 1.42\n",
      "  - Jack Rabbit: 2 entries -> avg rating 3.33\n",
      "  - Racer (Right): 2 entries -> avg rating 3.01\n",
      "  - Racer (Left): 2 entries -> avg rating 3.02\n",
      "  - Backlot Stunt Coaster: 2 entries -> avg rating 3.01\n",
      "  - Untamed: 2 entries -> avg rating 3.92\n",
      "  - Wilderness Run: 2 entries -> avg rating 1.52\n",
      "\n",
      "[OK] Final dataset: 359 unique coasters\n",
      "\n",
      "======================================================================\n",
      "DATASET STATISTICS\n",
      "======================================================================\n",
      "Total coasters: 359\n",
      "Rating range: 1.06 - 4.90\n",
      "Average rating: 3.29 +/- 0.91\n",
      "Total CSV files: 1198\n",
      "Average CSVs per coaster: 3.34\n",
      "\n",
      "Top 5 highest rated:\n",
      "  Zadra                          4.90* (1 CSVs)\n",
      "  AlpenFury                      4.88* (5 CSVs)\n",
      "  Taiga                          4.87* (4 CSVs)\n",
      "  VelociCoaster                  4.86* (5 CSVs)\n",
      "  ArieForce One                  4.83* (5 CSVs)\n",
      "\n",
      "Bottom 5 lowest rated:\n",
      "  Cocoa Cruiser                  1.29* (1 CSVs)\n",
      "  Kong                           1.28* (3 CSVs)\n",
      "  Howler                         1.22* (2 CSVs)\n",
      "  Spinning Out                   1.17* (2 CSVs)\n",
      "  Euromir                        1.06* (1 CSVs)\n",
      "\n",
      "[OK] Ready to train on 359 coasters\n"
     ]
    }
   ],
   "source": [
    "# Load and prepare the dataset\n",
    "coaster_mapping = prepare_training_data()\n",
    "\n",
    "print(f\"\\n[OK] Ready to train on {len(coaster_mapping)} coasters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load Accelerometer Data and Extract Features\n",
    "\n",
    "Load acceleration sequences and calculate airtime features for each coaster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PROCESSING ACCELEROMETER DATA\n",
      "======================================================================\n",
      "\n",
      "[DEBUG] First path in mapping: rfdb_csvs\\energylandia\\zadra\n",
      "[DEBUG] Path exists: True\n",
      "[DEBUG] CSV files found: 1\n",
      "[DEBUG] First file: rfdb_csvs/energylandia/zadra\\1734190639_3184.csv\n",
      "  Processed 50/359 coasters...\n",
      "  Processed 100/359 coasters...\n",
      "  Processed 150/359 coasters...\n",
      "  Processed 100/359 coasters...\n",
      "  Processed 150/359 coasters...\n",
      "  Processed 200/359 coasters...\n",
      "  Processed 200/359 coasters...\n",
      "  Processed 250/359 coasters...\n",
      "  Processed 300/359 coasters...\n",
      "  Processed 250/359 coasters...\n",
      "  Processed 300/359 coasters...\n",
      "  Processed 350/359 coasters...\n",
      "\n",
      "[OK] Successfully processed 354 coasters\n",
      "[!] Skipped 5 coasters (missing/invalid data)\n",
      "[OK] Generated 3355 training sequences\n",
      "\n",
      "Final dataset shape:\n",
      "  Sequences: (3355, 3, 1000)\n",
      "  Airtime features: (3355, 4)\n",
      "  Ratings: (3355,)\n",
      "  Processed 350/359 coasters...\n",
      "\n",
      "[OK] Successfully processed 354 coasters\n",
      "[!] Skipped 5 coasters (missing/invalid data)\n",
      "[OK] Generated 3355 training sequences\n",
      "\n",
      "Final dataset shape:\n",
      "  Sequences: (3355, 3, 1000)\n",
      "  Airtime features: (3355, 4)\n",
      "  Ratings: (3355,)\n"
     ]
    }
   ],
   "source": [
    "def process_accelerometer_data(coaster_mapping):\n",
    "    \"\"\"\n",
    "    Process all accelerometer files and extract features.\n",
    "    Returns sequences, airtime features, and ratings.\n",
    "    \"\"\"\n",
    "    all_sequences = []\n",
    "    all_airtime_features = []\n",
    "    all_ratings = []\n",
    "    all_coaster_names = []\n",
    "    \n",
    "    REQUIRED_COLUMNS = ['time', 'xforce', 'yforce', 'zforce']\n",
    "    ACCEL_COLUMNS = ['xforce', 'yforce', 'zforce']\n",
    "\n",
    "    skipped_count = 0\n",
    "    processed_count = 0\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"PROCESSING ACCELEROMETER DATA\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Check first path to verify directory structure\n",
    "    if len(coaster_mapping) > 0:\n",
    "        first_path = coaster_mapping.iloc[0]['full_path']\n",
    "        print(f\"\\n[DEBUG] First path in mapping: {first_path}\")\n",
    "        print(f\"[DEBUG] Path exists: {os.path.exists(first_path)}\")\n",
    "        if os.path.exists(first_path):\n",
    "            files = glob.glob(f\"{first_path.replace(chr(92), '/')}/*.csv\")\n",
    "            print(f\"[DEBUG] CSV files found: {len(files)}\")\n",
    "            if files:\n",
    "                print(f\"[DEBUG] First file: {files[0]}\")\n",
    "    \n",
    "    for idx, row in coaster_mapping.iterrows():\n",
    "        coaster_name = row['coaster_name']\n",
    "        full_path = row['full_path']\n",
    "        rating = row['avg_rating']\n",
    "        \n",
    "        # Load accelerometer data\n",
    "        accel_df = load_last_accelerometer_file(full_path)\n",
    "        \n",
    "        if accel_df is None:\n",
    "            skipped_count += 1\n",
    "            if skipped_count <= 3:  # Show first 3 failures for debugging\n",
    "                print(f\"[!] Failed to load: {coaster_name} at {full_path}\")\n",
    "            continue\n",
    "        \n",
    "        # Check for required columns\n",
    "        missing_cols = [col for col in REQUIRED_COLUMNS if col not in accel_df.columns]\n",
    "        if missing_cols:\n",
    "            skipped_count += 1\n",
    "            if skipped_count <= 3:\n",
    "                print(f\"[!] Missing columns for {coaster_name}: {missing_cols}\")\n",
    "                print(f\"    Available columns: {list(accel_df.columns)}\")\n",
    "            continue\n",
    "        \n",
    "        # Convert to numeric and drop NaN\n",
    "        for col in REQUIRED_COLUMNS:\n",
    "            accel_df[col] = pd.to_numeric(accel_df[col], errors='coerce')\n",
    "        accel_df = accel_df.dropna(subset=REQUIRED_COLUMNS)\n",
    "        \n",
    "        if len(accel_df) < SEQUENCE_LENGTH:\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "        \n",
    "        # Calculate airtime features\n",
    "        airtime_features = calculate_airtime(accel_df)\n",
    "        \n",
    "        # Extract acceleration sequences\n",
    "        data = accel_df[ACCEL_COLUMNS].values.T  # Shape: (3, num_timesteps)\n",
    "        \n",
    "        # Normalize (subtract 1g from vertical, divide all by 5g)\n",
    "        data[1, :] = data[1, :] - 1.0  # Vertical index is 1\n",
    "        data = data / 5.0\n",
    "        \n",
    "        # Create sequences with overlapping windows\n",
    "        num_timesteps = data.shape[1]\n",
    "        step_size = SEQUENCE_LENGTH // 4\n",
    "        \n",
    "        for start in range(0, num_timesteps - SEQUENCE_LENGTH + 1, step_size):\n",
    "            segment = data[:, start:start + SEQUENCE_LENGTH]\n",
    "            \n",
    "            if segment.shape[1] == SEQUENCE_LENGTH:\n",
    "                all_sequences.append(segment)\n",
    "                all_airtime_features.append(airtime_features)\n",
    "                all_ratings.append(rating)\n",
    "                all_coaster_names.append(coaster_name)\n",
    "        \n",
    "        processed_count += 1\n",
    "        if processed_count % 50 == 0:\n",
    "            print(f\"  Processed {processed_count}/{len(coaster_mapping)} coasters...\")\n",
    "    \n",
    "    print(f\"\\n[OK] Successfully processed {processed_count} coasters\")\n",
    "    print(f\"[!] Skipped {skipped_count} coasters (missing/invalid data)\")\n",
    "    print(f\"[OK] Generated {len(all_sequences)} training sequences\")\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    sequences = np.array(all_sequences, dtype=np.float32)  # (N, 3, seq_len)\n",
    "    airtime_features = np.array(all_airtime_features, dtype=np.float32)  # (N, 4)\n",
    "    ratings = np.array(all_ratings, dtype=np.float32)  # (N,)\n",
    "    \n",
    "    return sequences, airtime_features, ratings, all_coaster_names\n",
    "\n",
    "\n",
    "# Process all coasters\n",
    "sequences, airtime_features, ratings, coaster_names = process_accelerometer_data(coaster_mapping)\n",
    "\n",
    "print(f\"\\nFinal dataset shape:\")\n",
    "print(f\"  Sequences: {sequences.shape}\")\n",
    "print(f\"  Airtime features: {airtime_features.shape}\")\n",
    "print(f\"  Ratings: {ratings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create Dataset and DataLoaders\n",
    "\n",
    "Split data into train/val/test sets and create PyTorch DataLoaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "DATASET SPLIT\n",
      "======================================================================\n",
      "Train sequences: 2348\n",
      "Val sequences: 503\n",
      "Test sequences: 504\n",
      "Batch size: 16\n",
      "Train batches: 147\n",
      "Val batches: 32\n",
      "Test batches: 32\n"
     ]
    }
   ],
   "source": [
    "class CoasterDataset(Dataset):\n",
    "    \"\"\"PyTorch dataset for coaster sequences and airtime features.\"\"\"\n",
    "    \n",
    "    def __init__(self, sequences, airtime_features, ratings):\n",
    "        self.sequences = torch.from_numpy(sequences).float()\n",
    "        self.airtime_features = torch.from_numpy(airtime_features).float()\n",
    "        self.ratings = torch.from_numpy(ratings).float()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.sequences[idx], self.airtime_features[idx], self.ratings[idx]\n",
    "\n",
    "\n",
    "# Normalize features\n",
    "scaler_airtime = StandardScaler()\n",
    "scaler_ratings = StandardScaler()\n",
    "\n",
    "airtime_features_normalized = scaler_airtime.fit_transform(airtime_features)\n",
    "ratings_normalized = scaler_ratings.fit_transform(ratings.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Split data: 70% train, 15% val, 15% test\n",
    "indices = np.arange(len(sequences))\n",
    "train_idx, temp_idx = train_test_split(indices, test_size=0.3, random_state=42)\n",
    "val_idx, test_idx = train_test_split(temp_idx, test_size=0.5, random_state=42)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = CoasterDataset(\n",
    "    sequences[train_idx],\n",
    "    airtime_features_normalized[train_idx],\n",
    "    ratings_normalized[train_idx]\n",
    ")\n",
    "\n",
    "val_dataset = CoasterDataset(\n",
    "    sequences[val_idx],\n",
    "    airtime_features_normalized[val_idx],\n",
    "    ratings_normalized[val_idx]\n",
    ")\n",
    "\n",
    "test_dataset = CoasterDataset(\n",
    "    sequences[test_idx],\n",
    "    airtime_features_normalized[test_idx],\n",
    "    ratings_normalized[test_idx]\n",
    ")\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DATASET SPLIT\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Train sequences: {len(train_dataset)}\")\n",
    "print(f\"Val sequences: {len(val_dataset)}\")\n",
    "print(f\"Test sequences: {len(test_dataset)}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Define BiGRU Model\n",
    "\n",
    "Bidirectional GRU with airtime feature integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "MODEL ARCHITECTURE\n",
      "======================================================================\n",
      "BiGRURegressor(\n",
      "  (gru): GRU(3, 128, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n",
      "  (airtime_head): Sequential(\n",
      "    (0): Linear(in_features=4, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.15, inplace=False)\n",
      "  )\n",
      "  (head): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.3, inplace=False)\n",
      "    (6): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Total parameters: 530,817\n",
      "Trainable parameters: 530,817\n"
     ]
    }
   ],
   "source": [
    "class BiGRURegressor(nn.Module):\n",
    "    \"\"\"\n",
    "    Bidirectional GRU model for coaster rating prediction.\n",
    "    Combines accelerometer sequences with airtime features.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, accel_input_size=ACCEL_CHANNELS, airtime_feature_size=AIRTIME_FEATURE_COUNT,\n",
    "                 hidden_dim=HIDDEN_DIM, num_layers=NUM_LAYERS, dropout_rate=DROPOUT_RATE):\n",
    "        super(BiGRURegressor, self).__init__()\n",
    "        \n",
    "        # BiGRU for sequence processing\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=accel_input_size,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            dropout=dropout_rate if num_layers > 1 else 0\n",
    "        )\n",
    "        \n",
    "        # Process airtime features\n",
    "        self.airtime_head = nn.Sequential(\n",
    "            nn.Linear(airtime_feature_size, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate / 2)\n",
    "        )\n",
    "        \n",
    "        # Combined embedding size\n",
    "        final_input_size = (2 * hidden_dim) + hidden_dim\n",
    "        \n",
    "        # Regression head\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(final_input_size, hidden_dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x_accel, x_airtime):\n",
    "        # Process acceleration sequence\n",
    "        x_accel = x_accel.transpose(1, 2)  # (batch, channels, seq_len) -> (batch, seq_len, channels)\n",
    "        _, h_n = self.gru(x_accel)\n",
    "        \n",
    "        # Concatenate forward and backward hidden states\n",
    "        rnn_embedding = torch.cat((h_n[-2, :, :], h_n[-1, :, :]), dim=1)\n",
    "        \n",
    "        # Process airtime features\n",
    "        airtime_embedding = self.airtime_head(x_airtime)\n",
    "        \n",
    "        # Combine embeddings\n",
    "        combined_embedding = torch.cat((rnn_embedding, airtime_embedding), dim=1)\n",
    "        \n",
    "        # Final prediction\n",
    "        output = self.head(combined_embedding).squeeze(1)\n",
    "        \n",
    "        return output\n",
    "\n",
    "\n",
    "# Create model\n",
    "model = BiGRURegressor()\n",
    "model = model.to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL ARCHITECTURE\")\n",
    "print(\"=\"*70)\n",
    "print(model)\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Training Loop\n",
    "\n",
    "Train the model with early stopping and validation monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "TRAINING\n",
      "======================================================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 37\u001b[39m\n\u001b[32m     35\u001b[39m predictions = model(sequences, airtime_feats)\n\u001b[32m     36\u001b[39m loss = criterion(predictions, ratings)\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# Gradient clipping\u001b[39;00m\n\u001b[32m     40\u001b[39m torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=\u001b[32m1.0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\anaconda3\\envs\\rc\\Lib\\site-packages\\torch\\_tensor.py:625\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    617\u001b[39m         Tensor.backward,\n\u001b[32m    618\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    623\u001b[39m         inputs=inputs,\n\u001b[32m    624\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\anaconda3\\envs\\rc\\Lib\\site-packages\\torch\\autograd\\__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\anaconda3\\envs\\rc\\Lib\\site-packages\\torch\\autograd\\graph.py:841\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    840\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    842\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    844\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Setup optimizer and loss\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Learning rate scheduler (removed verbose parameter - deprecated in newer PyTorch versions)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "\n",
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'val_loss': [],\n",
    "    'val_r2': [],\n",
    "    'val_mse': []\n",
    "}\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "PATIENCE = 15\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for sequences, airtime_feats, ratings in train_loader:\n",
    "        sequences = sequences.to(device)\n",
    "        airtime_feats = airtime_feats.to(device)\n",
    "        ratings = ratings.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(sequences, airtime_feats)\n",
    "        loss = criterion(predictions, ratings)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    all_val_preds = []\n",
    "    all_val_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for sequences, airtime_feats, ratings in val_loader:\n",
    "            sequences = sequences.to(device)\n",
    "            airtime_feats = airtime_feats.to(device)\n",
    "            ratings = ratings.to(device)\n",
    "            \n",
    "            predictions = model(sequences, airtime_feats)\n",
    "            loss = criterion(predictions, ratings)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            all_val_preds.extend(predictions.cpu().numpy())\n",
    "            all_val_targets.extend(ratings.cpu().numpy())\n",
    "    \n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    val_r2 = r2_score(all_val_targets, all_val_preds)\n",
    "    val_mse = mean_squared_error(all_val_targets, all_val_preds)\n",
    "    \n",
    "    # Update history\n",
    "    history['train_loss'].append(avg_train_loss)\n",
    "    history['val_loss'].append(avg_val_loss)\n",
    "    history['val_r2'].append(val_r2)\n",
    "    history['val_mse'].append(val_mse)\n",
    "    \n",
    "    # Learning rate scheduling\n",
    "    old_lr = optimizer.param_groups[0]['lr']\n",
    "    scheduler.step(avg_val_loss)\n",
    "    new_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # Early stopping\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), 'best_bigru_model.pth')\n",
    "        best_marker = \" *\"\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        best_marker = \"\"\n",
    "    \n",
    "    # Print progress for every epoch\n",
    "    print(f\"Epoch {epoch+1:3d}/{NUM_EPOCHS} | \"\n",
    "          f\"Train: {avg_train_loss:.4f} | \"\n",
    "          f\"Val: {avg_val_loss:.4f} | \"\n",
    "          f\"R2: {val_r2:.4f}{best_marker}\")\n",
    "    \n",
    "    # Manually print LR change (since verbose was removed)\n",
    "    if new_lr != old_lr:\n",
    "        print(f\"  -> Learning rate reduced: {old_lr:.6f} -> {new_lr:.6f}\")\n",
    "    \n",
    "    # Early stopping check\n",
    "    if patience_counter >= PATIENCE:\n",
    "        print(f\"\\nEarly stopping triggered at epoch {epoch+1}\")\n",
    "        break\n",
    "\n",
    "print(\"\\n[OK] Training completed!\")\n",
    "print(f\"Best validation loss: {best_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Visualize Training History\n",
    "\n",
    "Plot training and validation losses over epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot losses\n",
    "axes[0].plot(history['train_loss'], label='Train Loss', linewidth=2)\n",
    "axes[0].plot(history['val_loss'], label='Val Loss', linewidth=2)\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss (MSE)')\n",
    "axes[0].set_title('Training and Validation Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot R2 score\n",
    "axes[1].plot(history['val_r2'], label='Val R2', color='green', linewidth=2)\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('R² Score')\n",
    "axes[1].set_title('Validation R² Score')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nFinal Training Loss: {history['train_loss'][-1]:.4f}\")\n",
    "print(f\"Final Validation Loss: {history['val_loss'][-1]:.4f}\")\n",
    "print(f\"Final Validation R²: {history['val_r2'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Evaluate on Test Set\n",
    "\n",
    "Load best model and evaluate on held-out test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "model.load_state_dict(torch.load('best_bigru_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Evaluate on test set\n",
    "test_loss = 0.0\n",
    "all_test_preds = []\n",
    "all_test_targets = []\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TEST SET EVALUATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for sequences, airtime_feats, ratings in test_loader:\n",
    "        sequences = sequences.to(device)\n",
    "        airtime_feats = airtime_feats.to(device)\n",
    "        ratings = ratings.to(device)\n",
    "        \n",
    "        predictions = model(sequences, airtime_feats)\n",
    "        loss = criterion(predictions, ratings)\n",
    "        test_loss += loss.item()\n",
    "        \n",
    "        all_test_preds.extend(predictions.cpu().numpy())\n",
    "        all_test_targets.extend(ratings.cpu().numpy())\n",
    "\n",
    "avg_test_loss = test_loss / len(test_loader)\n",
    "test_r2 = r2_score(all_test_targets, all_test_preds)\n",
    "test_mse = mean_squared_error(all_test_targets, all_test_preds)\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "\n",
    "# Denormalize predictions for interpretability\n",
    "all_test_preds_denorm = scaler_ratings.inverse_transform(np.array(all_test_preds).reshape(-1, 1)).flatten()\n",
    "all_test_targets_denorm = scaler_ratings.inverse_transform(np.array(all_test_targets).reshape(-1, 1)).flatten()\n",
    "\n",
    "# Calculate metrics on original scale\n",
    "test_r2_denorm = r2_score(all_test_targets_denorm, all_test_preds_denorm)\n",
    "test_mse_denorm = mean_squared_error(all_test_targets_denorm, all_test_preds_denorm)\n",
    "test_rmse_denorm = np.sqrt(test_mse_denorm)\n",
    "\n",
    "print(f\"\\nNormalized Metrics:\")\n",
    "print(f\"  Test Loss: {avg_test_loss:.4f}\")\n",
    "print(f\"  Test R²: {test_r2:.4f}\")\n",
    "print(f\"  Test MSE: {test_mse:.4f}\")\n",
    "print(f\"  Test RMSE: {test_rmse:.4f}\")\n",
    "\n",
    "print(f\"\\nOriginal Scale Metrics:\")\n",
    "print(f\"  Test R²: {test_r2_denorm:.4f}\")\n",
    "print(f\"  Test MSE: {test_mse_denorm:.4f}\")\n",
    "print(f\"  Test RMSE: {test_rmse_denorm:.4f}\")\n",
    "print(f\"  Mean Absolute Error: {np.mean(np.abs(all_test_targets_denorm - all_test_preds_denorm)):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Prediction vs Actual Visualization\n",
    "\n",
    "Compare model predictions with actual ratings on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Scatter plot\n",
    "axes[0].scatter(all_test_targets_denorm, all_test_preds_denorm, alpha=0.5, s=20)\n",
    "axes[0].plot([min(all_test_targets_denorm), max(all_test_targets_denorm)],\n",
    "             [min(all_test_targets_denorm), max(all_test_targets_denorm)],\n",
    "             'r--', linewidth=2, label='Perfect Prediction')\n",
    "axes[0].set_xlabel('Actual Rating')\n",
    "axes[0].set_ylabel('Predicted Rating')\n",
    "axes[0].set_title(f'Predictions vs Actual (R² = {test_r2_denorm:.3f})')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Residual plot\n",
    "residuals = all_test_targets_denorm - all_test_preds_denorm\n",
    "axes[1].scatter(all_test_preds_denorm, residuals, alpha=0.5, s=20)\n",
    "axes[1].axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "axes[1].set_xlabel('Predicted Rating')\n",
    "axes[1].set_ylabel('Residual (Actual - Predicted)')\n",
    "axes[1].set_title('Residual Plot')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show some example predictions\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SAMPLE PREDICTIONS\")\n",
    "print(\"=\"*70)\n",
    "sample_indices = np.random.choice(len(all_test_targets_denorm), min(10, len(all_test_targets_denorm)), replace=False)\n",
    "for idx in sample_indices:\n",
    "    actual = all_test_targets_denorm[idx]\n",
    "    predicted = all_test_preds_denorm[idx]\n",
    "    error = abs(actual - predicted)\n",
    "    print(f\"Actual: {actual:.2f} | Predicted: {predicted:.2f} | Error: {error:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Save Model and Scalers\n",
    "\n",
    "Save the trained model and scalers for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save model\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'model_config': {\n",
    "        'accel_input_size': ACCEL_CHANNELS,\n",
    "        'airtime_feature_size': AIRTIME_FEATURE_COUNT,\n",
    "        'hidden_dim': HIDDEN_DIM,\n",
    "        'num_layers': NUM_LAYERS,\n",
    "        'dropout_rate': DROPOUT_RATE\n",
    "    },\n",
    "    'train_config': {\n",
    "        'sequence_length': SEQUENCE_LENGTH,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'learning_rate': LEARNING_RATE,\n",
    "        'num_epochs': NUM_EPOCHS\n",
    "    }\n",
    "}, 'bigru_rating_model.pth')\n",
    "\n",
    "# Save scalers\n",
    "with open('scaler_airtime.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler_airtime, f)\n",
    "\n",
    "with open('scaler_ratings.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler_ratings, f)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL SAVED\")\n",
    "print(\"=\"*70)\n",
    "print(\"Files saved:\")\n",
    "print(\"  - bigru_rating_model.pth (model weights + config)\")\n",
    "print(\"  - scaler_airtime.pkl (airtime feature scaler)\")\n",
    "print(\"  - scaler_ratings.pkl (rating scaler)\")\n",
    "print(\"\\nTo load the model:\")\n",
    "print(\"  checkpoint = torch.load('bigru_rating_model.pth')\")\n",
    "print(\"  model = BiGRURegressor(**checkpoint['model_config'])\")\n",
    "print(\"  model.load_state_dict(checkpoint['model_state_dict'])\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook provides a complete pipeline for:\n",
    "\n",
    "1. **Data Loading**: Load coaster mapping from `complete_coaster_mapping.csv`\n",
    "2. **Data Filtering**: Filter for perfect matches (≥95% similarity)\n",
    "3. **Duplicate Handling**: Average ratings for duplicate coaster names\n",
    "4. **Feature Extraction**: \n",
    "   - Accelerometer sequences (3-axis: Lateral, Vertical, Longitudinal)\n",
    "   - Airtime features (total airtime, max negative g, airtime moments, avg duration)\n",
    "5. **Model Training**: Bidirectional GRU with airtime feature integration\n",
    "6. **Evaluation**: R², MSE, RMSE on test set\n",
    "7. **Model Saving**: Save trained model and scalers for deployment\n",
    "\n",
    "**Key Results:**\n",
    "- Dataset: 359 unique coasters after filtering and aggregation\n",
    "- Rating range: 1.06 - 4.90 stars\n",
    "- Model: BiGRU with ~{trainable_params:,} trainable parameters\n",
    "- Test R²: {test_r2_denorm:.4f}\n",
    "- Test RMSE: {test_rmse_denorm:.4f} stars\n",
    "\n",
    "The trained model can now be used in production for rating prediction from accelerometer data!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "rc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
